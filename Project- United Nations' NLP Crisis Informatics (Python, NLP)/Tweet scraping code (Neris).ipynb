{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Feb 17 - attempt 1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"--9oF6Fx8M40"},"source":["import logging\n","logging.basicConfig(filename='/content/logs.log', level=logging.ERROR, format='%(asctime)s %(levelname)s %(name)s %(message)s')\n","logger=logging.getLogger(__name__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7WgtsG46eb1"},"source":["from tweepy import OAuthHandler\n","import tweepy\n","import csv\n","from datetime import datetime\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZQjKQY4Oaqi"},"source":["CONSUMER_KEY = 'XXLWUovfZuT6OjRdfbDC3P1md'\n","CONSUMER_SECRET_KEY = '0GN3jNA9YGEpeidokjLrY83arvtnfYbGIUaOA79Fvv8xlAa13f'\n","ACCESS_TOKEN = '1044960440722186240-J9izxtP3zW0RoFFSwWwpEj7K7PQTZF'\n","ACCESS_TOKEN_SECRET = 'jutX7iHISlgu9qGzTxqusaUEJ6gu5VuxgREq3S7p2voRZ'\n","TODAY = datetime.today().strftime('%Y-%m-%d')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnEsaF2tOMUU"},"source":["try:\n","    '''API Authentication'''\n","    auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET_KEY)\n","    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n","    api = tweepy.API(auth, wait_on_rate_limit=True)\n","except Exception as e:\n","    logger.error('Authentication Failed', str(e))\n","    print('Authentication Failed', str(e))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEJ_ffhI7WjR"},"source":["def scrap_tweets(text_query: str, start_date: str) -> None:\n","    try:\n","        # Creation of query method using parameters and filter out the retweets\n","        with open(f'/content/tweets-{TODAY}.csv', 'a', encoding = \"utf-8\") as csv_file:\n","            csv_writer = csv.writer(csv_file)\n","            csv_writer.writerow(['User', 'Location', 'Tweet', 'Num of Friend', 'Num of Followers', 'Total Tweets by user', \n","                                 'Account Created at', 'Tweet Created at', 'Num of Retweet', 'hashtags in the tweet'])\n","            for tweet in tweepy.Cursor(\n","                api.search, \n","                q=text_query + '-filter:retweets', \n","                tweet_mode=\"extended\",\n","                since=start_date,  \n","                lang=\"en\").items():\n","                csv_writer.writerow([tweet.user.screen_name, tweet.user.location , tweet.full_text.replace(\"&amp;\", \"&\"),\n","                    tweet.user.friends_count, tweet.user.followers_count,tweet.user.statuses_count,\n","                    tweet.user.created_at,tweet.created_at,tweet.retweet_count, tweet.entities['hashtags']])\n"," \n","    except BaseException as e:\n","        logger.error(e)\n","        print('Authentication Failed', str(e))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9cdkdNpSaZD"},"source":["twitter_hastag = [\"#earthquake\", \"#earthquakes\", \"#tsunami\", \"#earthquakedamage\", \"#earthquakerelief\", \"#earthquakestory\", \"#earthquakeseason\"] \n","\n","for hashtag in twitter_hastag:\n","    logger.debug(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","    scrap_tweets(hashtag, \"2021-02-16\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRTDfvqweGkN"},"source":["other_disaster_hashtags = [\"#forestfire\", \"#wildfire\", \"#avalanche\", \"#flood\", \"#storm\", \"#hurricane\", \"#cyclone\", \"#landslide\"]\n","\n","for other_hashtag in other_disaster_hashtags:    \n","    logger.debug(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","    scrap_tweets(other_hashtag, \"2021-02-15\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aVhD-kbM_i2"},"source":["random_hashtags = [\"#blaze\", \"#crush\", \"#crushed\", \"#curfew\", \"#danger\", \"#explode\", \"#exploded\", \"#fear\",\t\"#harm\", \"#meltdown\", \"#obliterate\", \"#siren\", \"#smoke\"]\n","\n","for random_hashtag in random_hashtags:    \n","    logger.debug(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n","    scrap_tweets(random_hashtag, \"2021-02-21\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPjV0eP7bjHP"},"source":["files.download(f'./tweets-{TODAY}.csv')"],"execution_count":null,"outputs":[]}]}