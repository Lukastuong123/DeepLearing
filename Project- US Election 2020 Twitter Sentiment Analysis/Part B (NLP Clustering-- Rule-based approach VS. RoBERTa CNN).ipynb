{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='red' size=\"6\"> **IV/Sentiment analysis (Rule-based approach with subjectivity- polarity)** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Num of Friend</th>\n",
       "      <th>Num of Followers</th>\n",
       "      <th>Total Tweets by user</th>\n",
       "      <th>Account Created at</th>\n",
       "      <th>Tweet Created at</th>\n",
       "      <th>Num of Retweet</th>\n",
       "      <th>hashtags in the tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>word_way</th>\n",
       "      <th>word_week</th>\n",
       "      <th>word_white</th>\n",
       "      <th>word_win</th>\n",
       "      <th>word_wins</th>\n",
       "      <th>word_world</th>\n",
       "      <th>word_year</th>\n",
       "      <th>word_years</th>\n",
       "      <th>word_yes</th>\n",
       "      <th>dt_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thekumachan</td>\n",
       "      <td>n.a</td>\n",
       "      <td>Kamala Harris Knows How to Win Contest\\nhttps:...</td>\n",
       "      <td>23</td>\n",
       "      <td>60</td>\n",
       "      <td>4218</td>\n",
       "      <td>2009-08-21 22:01:59</td>\n",
       "      <td>2020-10-26 23:00:31</td>\n",
       "      <td>0</td>\n",
       "      <td>['2020campaign', '2020election', 'amateur', 'b...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>washington d.c.</td>\n",
       "      <td>realDonaldTrump gained 3,412 Twitter followers...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6642</td>\n",
       "      <td>2019-12-30 23:45:24</td>\n",
       "      <td>2020-10-26 23:00:21</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>washington d.c.</td>\n",
       "      <td>JoeBiden gained 11,515 Twitter followers in th...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6642</td>\n",
       "      <td>2019-12-30 23:45:24</td>\n",
       "      <td>2020-10-26 23:00:21</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>washington d.c.</td>\n",
       "      <td>Mike_Pence gained 1,684 Twitter followers in t...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6642</td>\n",
       "      <td>2019-12-30 23:45:24</td>\n",
       "      <td>2020-10-26 23:00:21</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>washington d.c.</td>\n",
       "      <td>KamalaHarris gained 7,302 Twitter followers in...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>6642</td>\n",
       "      <td>2019-12-30 23:45:24</td>\n",
       "      <td>2020-10-26 23:00:21</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>ByDionne</td>\n",
       "      <td>n.a</td>\n",
       "      <td>üíöüôåüòÄü•≥üòáüôèLet's Win This!! #VoteEarly #VOTE  Let's...</td>\n",
       "      <td>2961</td>\n",
       "      <td>1743</td>\n",
       "      <td>10803</td>\n",
       "      <td>2012-05-07 12:29:39</td>\n",
       "      <td>2020-10-26 21:02:58</td>\n",
       "      <td>0</td>\n",
       "      <td>['voteearly', 'vote']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>Iamjasbirkaur</td>\n",
       "      <td>olney, md</td>\n",
       "      <td>Saving democracy! \\n#VOTE #VoteHimOut2020 #Vot...</td>\n",
       "      <td>622</td>\n",
       "      <td>359</td>\n",
       "      <td>3432</td>\n",
       "      <td>2014-07-19 15:43:08</td>\n",
       "      <td>2020-10-26 21:02:56</td>\n",
       "      <td>0</td>\n",
       "      <td>['vote', 'votehimout2020', 'votebidenharris2020']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>enelson6</td>\n",
       "      <td>n.a</td>\n",
       "      <td>@CornynResponse @JohnCornyn @mjhegar #Vote @mj...</td>\n",
       "      <td>1057</td>\n",
       "      <td>413</td>\n",
       "      <td>21866</td>\n",
       "      <td>2009-01-02 12:22:53</td>\n",
       "      <td>2020-10-26 21:02:54</td>\n",
       "      <td>0</td>\n",
       "      <td>['vote']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>ethannichtern</td>\n",
       "      <td>n.a</td>\n",
       "      <td>Happiness: Noun. \\n\\nThat feeling where you ar...</td>\n",
       "      <td>939</td>\n",
       "      <td>13441</td>\n",
       "      <td>27261</td>\n",
       "      <td>2009-03-11 21:56:10</td>\n",
       "      <td>2020-10-26 21:02:53</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>LdyDisney</td>\n",
       "      <td>fort pierce, fl</td>\n",
       "      <td>Get out there and #VoteHimOut2020 #VoteEarly #...</td>\n",
       "      <td>14301</td>\n",
       "      <td>14217</td>\n",
       "      <td>107340</td>\n",
       "      <td>2008-08-01 01:54:46</td>\n",
       "      <td>2020-10-26 21:02:48</td>\n",
       "      <td>0</td>\n",
       "      <td>['votehimout2020', 'voteearly', 'vote']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20159 rows √ó 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User         Location  \\\n",
       "0        thekumachan              n.a   \n",
       "1      2020Followers  washington d.c.   \n",
       "2      2020Followers  washington d.c.   \n",
       "3      2020Followers  washington d.c.   \n",
       "4      2020Followers  washington d.c.   \n",
       "...              ...              ...   \n",
       "20154       ByDionne              n.a   \n",
       "20155  Iamjasbirkaur        olney, md   \n",
       "20156       enelson6              n.a   \n",
       "20157  ethannichtern              n.a   \n",
       "20158      LdyDisney  fort pierce, fl   \n",
       "\n",
       "                                                   Tweet  Num of Friend  \\\n",
       "0      Kamala Harris Knows How to Win Contest\\nhttps:...             23   \n",
       "1      realDonaldTrump gained 3,412 Twitter followers...              1   \n",
       "2      JoeBiden gained 11,515 Twitter followers in th...              1   \n",
       "3      Mike_Pence gained 1,684 Twitter followers in t...              1   \n",
       "4      KamalaHarris gained 7,302 Twitter followers in...              1   \n",
       "...                                                  ...            ...   \n",
       "20154  üíöüôåüòÄü•≥üòáüôèLet's Win This!! #VoteEarly #VOTE  Let's...           2961   \n",
       "20155  Saving democracy! \\n#VOTE #VoteHimOut2020 #Vot...            622   \n",
       "20156  @CornynResponse @JohnCornyn @mjhegar #Vote @mj...           1057   \n",
       "20157  Happiness: Noun. \\n\\nThat feeling where you ar...            939   \n",
       "20158  Get out there and #VoteHimOut2020 #VoteEarly #...          14301   \n",
       "\n",
       "       Num of Followers  Total Tweets by user   Account Created at  \\\n",
       "0                    60                  4218  2009-08-21 22:01:59   \n",
       "1                    31                  6642  2019-12-30 23:45:24   \n",
       "2                    31                  6642  2019-12-30 23:45:24   \n",
       "3                    31                  6642  2019-12-30 23:45:24   \n",
       "4                    31                  6642  2019-12-30 23:45:24   \n",
       "...                 ...                   ...                  ...   \n",
       "20154              1743                 10803  2012-05-07 12:29:39   \n",
       "20155               359                  3432  2014-07-19 15:43:08   \n",
       "20156               413                 21866  2009-01-02 12:22:53   \n",
       "20157             13441                 27261  2009-03-11 21:56:10   \n",
       "20158             14217                107340  2008-08-01 01:54:46   \n",
       "\n",
       "          Tweet Created at  Num of Retweet  \\\n",
       "0      2020-10-26 23:00:31               0   \n",
       "1      2020-10-26 23:00:21               0   \n",
       "2      2020-10-26 23:00:21               0   \n",
       "3      2020-10-26 23:00:21               0   \n",
       "4      2020-10-26 23:00:21               0   \n",
       "...                    ...             ...   \n",
       "20154  2020-10-26 21:02:58               0   \n",
       "20155  2020-10-26 21:02:56               0   \n",
       "20156  2020-10-26 21:02:54               0   \n",
       "20157  2020-10-26 21:02:53               1   \n",
       "20158  2020-10-26 21:02:48               0   \n",
       "\n",
       "                                   hashtags in the tweet  ... word_way  \\\n",
       "0      ['2020campaign', '2020election', 'amateur', 'b...  ...      0.0   \n",
       "1                                                     []  ...      0.0   \n",
       "2                                                     []  ...      0.0   \n",
       "3                                                     []  ...      0.0   \n",
       "4                                                     []  ...      0.0   \n",
       "...                                                  ...  ...      ...   \n",
       "20154                              ['voteearly', 'vote']  ...      0.0   \n",
       "20155  ['vote', 'votehimout2020', 'votebidenharris2020']  ...      0.0   \n",
       "20156                                           ['vote']  ...      0.0   \n",
       "20157                                                 []  ...      0.0   \n",
       "20158            ['votehimout2020', 'voteearly', 'vote']  ...      0.0   \n",
       "\n",
       "      word_week  word_white  word_win  word_wins  word_world  word_year  \\\n",
       "0           0.0         0.0  1.000000        0.0         0.0        0.0   \n",
       "1           0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "2           0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "3           0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "4           0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "...         ...         ...       ...        ...         ...        ...   \n",
       "20154       0.0         0.0  0.455499        0.0         0.0        0.0   \n",
       "20155       0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "20156       0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "20157       0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "20158       0.0         0.0  0.000000        0.0         0.0        0.0   \n",
       "\n",
       "       word_years  word_yes     dt_date  \n",
       "0             0.0       0.0  2020-10-26  \n",
       "1             0.0       0.0  2020-10-26  \n",
       "2             0.0       0.0  2020-10-26  \n",
       "3             0.0       0.0  2020-10-26  \n",
       "4             0.0       0.0  2020-10-26  \n",
       "...           ...       ...         ...  \n",
       "20154         0.0       0.0  2020-10-26  \n",
       "20155         0.0       0.0  2020-10-26  \n",
       "20156         0.0       0.0  2020-10-26  \n",
       "20157         0.0       0.0  2020-10-26  \n",
       "20158         0.0       0.0  2020-10-26  \n",
       "\n",
       "[20159 rows x 129 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataframe\n",
    "data = pd.read_csv(os.getcwd() + '/data/' + '/Final_Data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **No. of Positive Sentiments vs No. of Negative Sentiments** </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at what is the overall distribution of positive and negative tweets. Based on the SentimentIntensityAnalyzer from the NLTK Vader-Lexicon library, this analyzer examines the sentiment of a sentence, on how positive neutral or negative it is. Since it is cirumstancial to the parties/ candidates, it would be better to do a seperate analysis in the end to know who is the target of the negative and positive connotations. \n",
    "\n",
    "The analyzer returns 4 scores for each sentence (positive, negative, neutral, compound). The score \"compound\" is the overal sentiment of the sentence in range [-1, 1]. For now, we want to classify each tweets into 5 different empition and assign a range of values for each of them: \n",
    "1. Very positive '5' - [0.55, 1.00]\n",
    "2. Positive '4' - [0.10, 0.55)\n",
    "3. Neutral '3' - (-0.10, 0.10)\n",
    "4. Negative '2' - (-0.55, -0.10]\n",
    "5. Very negative '1' - [-1.00, -0.55] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20149    3\n",
       "20150    3\n",
       "20151    3\n",
       "20152    3\n",
       "20153    5\n",
       "20154    5\n",
       "20155    3\n",
       "20156    3\n",
       "20157    5\n",
       "20158    3\n",
       "Name: sentiment_class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus on the \"compound\" scores \n",
    "#Create a new column called \"sentiment_class\"\n",
    "sentimentclass_list = []\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    #current 'compound' score:\n",
    "    curr_compound = data.iloc[i,:]['compound']\n",
    "    \n",
    "    if (curr_compound >= 0.55 and curr_compound <= 1.0 ):\n",
    "        sentimentclass_list.append(5)\n",
    "    elif (curr_compound >= 0.10 and curr_compound < 0.55 ):\n",
    "        sentimentclass_list.append(4)\n",
    "    elif (curr_compound > -0.10 and curr_compound < 0.10 ):\n",
    "        sentimentclass_list.append(3)\n",
    "    elif (curr_compound > -0.55 and curr_compound <= -0.10 ):\n",
    "        sentimentclass_list.append(2)\n",
    "    elif (curr_compound >= -1.0 and curr_compound <= -0.55 ):\n",
    "        sentimentclass_list.append(1)\n",
    "        \n",
    "        \n",
    "#Add the new column 'sentiment_class' to the dataframe \n",
    "data['sentiment_class'] = sentimentclass_list\n",
    "\n",
    "#Check the new column\n",
    "data.tail(10)['sentiment_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5859</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.5267</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7506</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.4588</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound  sentiment_class\n",
       "0    0.5859                5\n",
       "1    0.5994                5\n",
       "2    0.5994                5\n",
       "3    0.5994                5\n",
       "4    0.5994                5\n",
       "5    0.4404                4\n",
       "6    0.0000                3\n",
       "7   -0.5267                2\n",
       "8    0.7506                5\n",
       "9   -0.4588                2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify if the classification assignment is correct \n",
    "data.iloc[0:10,:][['compound', 'sentiment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of sentiment_class\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.set_palette('PuBuGn_d')\n",
    "sns.countplot(data['sentiment_class'])\n",
    "plt.title('Histogram of sentiment_class')\n",
    "plt.xlabel('sentiment_class')\n",
    "plt.ylabel('No. of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 random negative tweets and sentiment classes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14379</th>\n",
       "      <td>Latest opinion poll averages for #Donald #Trump and #JoeBiden in each of the 6 key battleground states of the 2020‚Ä¶ https://t.co/Ea3DTnCK24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Have questions about how to submit your absentee ballot? Need to ask a question about your voter registration statu‚Ä¶ https://t.co/GRhMB3vXBB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18366</th>\n",
       "      <td>Coming Soon to The Debating Times;\\n\\nWith the clock counting down to a damaging No Deal Brexit and a winter Covid cr‚Ä¶ https://t.co/NzbCu5ydKR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>@MikeVanriel2 The hell of it is that Trump will still have his cult of idolators and corrupt Republican legislators‚Ä¶ https://t.co/aFHqYC4xbw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22589</th>\n",
       "      <td>It is time to cease the fear mongering and open up the country and get EVERYONE back to work. @BorisJohnson if the‚Ä¶ https://t.co/XXOMyoVX8y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>@tamrobinson1966 If #Liberal Toronto voters drop another liberal candidate in position in bye Elections, then they‚Ä¶ https://t.co/cuEmpEya2o</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>those people are really ugly under all the make up and surgery #HuntersLapTop #HunterBiden #2020Election #democats‚Ä¶ https://t.co/rGr6X6QTdj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>@BarackObama It is really quite sad that an ex-president has to get involved in the #USElection2020 and it's even w‚Ä¶ https://t.co/0J2hTqZTyv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19673</th>\n",
       "      <td>COVID-19 is real, but the panic narrative that's been woven around it is entirely manufactured. The panic #politics‚Ä¶ https://t.co/ckroaokuEQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24441</th>\n",
       "      <td>\"We're supposed to be outraged because Amy Coney Barrett believes in life and we're not supposed to be outraged tha‚Ä¶ https://t.co/OdSSQbi3BC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                Tweet  \\\n",
       "14379  Latest opinion poll averages for #Donald #Trump and #JoeBiden in each of the 6 key battleground states of the 2020‚Ä¶ https://t.co/Ea3DTnCK24      \n",
       "67     Have questions about how to submit your absentee ballot? Need to ask a question about your voter registration statu‚Ä¶ https://t.co/GRhMB3vXBB     \n",
       "18366  Coming Soon to The Debating Times;\\n\\nWith the clock counting down to a damaging No Deal Brexit and a winter Covid cr‚Ä¶ https://t.co/NzbCu5ydKR   \n",
       "4456   @MikeVanriel2 The hell of it is that Trump will still have his cult of idolators and corrupt Republican legislators‚Ä¶ https://t.co/aFHqYC4xbw     \n",
       "22589  It is time to cease the fear mongering and open up the country and get EVERYONE back to work. @BorisJohnson if the‚Ä¶ https://t.co/XXOMyoVX8y      \n",
       "7228   @tamrobinson1966 If #Liberal Toronto voters drop another liberal candidate in position in bye Elections, then they‚Ä¶ https://t.co/cuEmpEya2o      \n",
       "895    those people are really ugly under all the make up and surgery #HuntersLapTop #HunterBiden #2020Election #democats‚Ä¶ https://t.co/rGr6X6QTdj      \n",
       "3993   @BarackObama It is really quite sad that an ex-president has to get involved in the #USElection2020 and it's even w‚Ä¶ https://t.co/0J2hTqZTyv     \n",
       "19673  COVID-19 is real, but the panic narrative that's been woven around it is entirely manufactured. The panic #politics‚Ä¶ https://t.co/ckroaokuEQ     \n",
       "24441  \"We're supposed to be outraged because Amy Coney Barrett believes in life and we're not supposed to be outraged tha‚Ä¶ https://t.co/OdSSQbi3BC     \n",
       "\n",
       "       sentiment_class  \n",
       "14379  2                \n",
       "67     2                \n",
       "18366  2                \n",
       "4456   1                \n",
       "22589  1                \n",
       "7228   2                \n",
       "895    1                \n",
       "3993   1                \n",
       "19673  1                \n",
       "24441  1                "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display full text: \n",
    "pd.set_option('display.max_colwidth', -2)\n",
    "\n",
    "#Look at some example of negative, neutral and positive tweets\n",
    "\n",
    "#Filter 5 negative tweets: \n",
    "print(\"10 random negative tweets and sentiment classes:\")\n",
    "data[(data['sentiment_class'] == 1) | (data['sentiment_class'] == 2)].sample(n=10)[['Tweet', 'sentiment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 random neutral tweets and sentiment classes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11351</th>\n",
       "      <td>#Mail-in #voting is an option this year for more American #voters than ever. But the rules depend on where you live‚Ä¶ https://t.co/WfazXXs0Oj</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28612</th>\n",
       "      <td>Our workshop is tomorrow at 2pm ET!! This won‚Äôt be your run of a mill poll working workshop either. You won‚Äôt want‚Ä¶ https://t.co/jHzHTuxrDB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>I cast my #vote today for #BidenHarris2020! #BidenHarrisLandslide2020 #BidenHarris2020Landslide #2020Election‚Ä¶ https://t.co/RdV0DhURBp</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8828</th>\n",
       "      <td>Joe on fracking #Biden #election https://t.co/3uqlNSoVqI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10507</th>\n",
       "      <td>Should Investors Prepare for the Likelihood of Post-Election Unrest? https://t.co/vddOeAlMJo @Alemid #investors‚Ä¶ https://t.co/Wq5vR0vkZb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>Oct. 24, 1960 - In Pittsburgh last night, Vice President Nixon decried Mr. Kennedy's \"silly and immature suggestion‚Ä¶ https://t.co/PDM2ciVWcV</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28397</th>\n",
       "      <td>Rock the #vote, keep the #faith! https://t.co/E6sM8P9hsO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>‚ö†Ô∏è7 Steps for Judging Candidates ‚ö†Ô∏è \\nAre you registered to vote? Next up - How to Judge a Candidate. The 7 steps we‚Ä¶ https://t.co/yXhb0RMDyS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>.@McAllenISD high schools. @ACHIEVE_MISD is in the lead!!\\n#RGV #2020election #mcallentx https://t.co/T2z29xJdeR</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19711</th>\n",
       "      <td>The way politicians (of every color) are using the virus to bring ahead their own ideologies and agenda and go agai‚Ä¶ https://t.co/qTh4DU4QKp</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               Tweet  \\\n",
       "11351  #Mail-in #voting is an option this year for more American #voters than ever. But the rules depend on where you live‚Ä¶ https://t.co/WfazXXs0Oj    \n",
       "28612  Our workshop is tomorrow at 2pm ET!! This won‚Äôt be your run of a mill poll working workshop either. You won‚Äôt want‚Ä¶ https://t.co/jHzHTuxrDB     \n",
       "10954  I cast my #vote today for #BidenHarris2020! #BidenHarrisLandslide2020 #BidenHarris2020Landslide #2020Election‚Ä¶ https://t.co/RdV0DhURBp          \n",
       "8828   Joe on fracking #Biden #election https://t.co/3uqlNSoVqI                                                                                        \n",
       "10507  Should Investors Prepare for the Likelihood of Post-Election Unrest? https://t.co/vddOeAlMJo @Alemid #investors‚Ä¶ https://t.co/Wq5vR0vkZb        \n",
       "11263  Oct. 24, 1960 - In Pittsburgh last night, Vice President Nixon decried Mr. Kennedy's \"silly and immature suggestion‚Ä¶ https://t.co/PDM2ciVWcV    \n",
       "28397  Rock the #vote, keep the #faith! https://t.co/E6sM8P9hsO                                                                                        \n",
       "2695   ‚ö†Ô∏è7 Steps for Judging Candidates ‚ö†Ô∏è \\nAre you registered to vote? Next up - How to Judge a Candidate. The 7 steps we‚Ä¶ https://t.co/yXhb0RMDyS   \n",
       "2056   .@McAllenISD high schools. @ACHIEVE_MISD is in the lead!!\\n#RGV #2020election #mcallentx https://t.co/T2z29xJdeR                                \n",
       "19711  The way politicians (of every color) are using the virus to bring ahead their own ideologies and agenda and go agai‚Ä¶ https://t.co/qTh4DU4QKp    \n",
       "\n",
       "       sentiment_class  \n",
       "11351  3                \n",
       "28612  3                \n",
       "10954  3                \n",
       "8828   3                \n",
       "10507  3                \n",
       "11263  3                \n",
       "28397  3                \n",
       "2695   3                \n",
       "2056   3                \n",
       "19711  3                "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter 10 neutral tweets: \n",
    "print(\"10 random neutral tweets and sentiment classes:\")\n",
    "data[(data['sentiment_class'] == 3)].sample(n=10)[['Tweet', 'sentiment_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 random positive tweets and sentiment classes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>Felt so good to vote today #VOTE #VoteEarly #VoteEarlyDay  #JoeBiden #KamalaHarris #BidenHarris @JoeBiden‚Ä¶ https://t.co/p7XZ2GsCvV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>@poccrt @ksorbs Could very well be the #strategy. I tend to think #Biden and #KamalaHarris are #candidates the‚Ä¶ https://t.co/LCivqxMHP8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>\"#POTUS News: #Trump top campaign adviser: 'The president wants to see every #Republican reelected' #News\": https://t.co/Pju4gF34SY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>Does this mean Warren has to support Trump now?\\nüòâ #Trump2020 #RedWave #MAGA https://t.co/RmiWqIEIdi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>The Search of Truth- without @realDonaldTrump none of us who served in VTNWar but came home to be spat on by those‚Ä¶ https://t.co/3Rbkxz59oE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20268</th>\n",
       "      <td>@JoeBiden Thank you.\\nIt is not a political statement, #BlackLivesMatter.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19525</th>\n",
       "      <td>@grahamctv OK, but is it possible that @JimWatsonOttawa changed his views due to lack of supporting date?  It is po‚Ä¶ https://t.co/hdDn38cOzh</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25060</th>\n",
       "      <td>@Patrici15767099 Some Entertainment Bosses had to inform #50cent that if he was endorsing #Trump ,  that he would h‚Ä¶ https://t.co/vSw1XZyi1b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>#JoeBiden and his family made millions from #China under the table. For the sake of the United States of America...‚Ä¶ https://t.co/DVr6jrE1u0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16971</th>\n",
       "      <td>Thank you @LindseyGrahamSC &amp;amp; @realDonaldTrump for everything #MAGA #KAG #Trump2020 https://t.co/QZUlkGh7hy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              Tweet  \\\n",
       "13653  Felt so good to vote today #VOTE #VoteEarly #VoteEarlyDay  #JoeBiden #KamalaHarris #BidenHarris @JoeBiden‚Ä¶ https://t.co/p7XZ2GsCvV             \n",
       "2959   @poccrt @ksorbs Could very well be the #strategy. I tend to think #Biden and #KamalaHarris are #candidates the‚Ä¶ https://t.co/LCivqxMHP8        \n",
       "21449  \"#POTUS News: #Trump top campaign adviser: 'The president wants to see every #Republican reelected' #News\": https://t.co/Pju4gF34SY            \n",
       "16003  Does this mean Warren has to support Trump now?\\nüòâ #Trump2020 #RedWave #MAGA https://t.co/RmiWqIEIdi                                           \n",
       "5737   The Search of Truth- without @realDonaldTrump none of us who served in VTNWar but came home to be spat on by those‚Ä¶ https://t.co/3Rbkxz59oE    \n",
       "20268  @JoeBiden Thank you.\\nIt is not a political statement, #BlackLivesMatter.                                                                      \n",
       "19525  @grahamctv OK, but is it possible that @JimWatsonOttawa changed his views due to lack of supporting date?  It is po‚Ä¶ https://t.co/hdDn38cOzh   \n",
       "25060  @Patrici15767099 Some Entertainment Bosses had to inform #50cent that if he was endorsing #Trump ,  that he would h‚Ä¶ https://t.co/vSw1XZyi1b   \n",
       "12448  #JoeBiden and his family made millions from #China under the table. For the sake of the United States of America...‚Ä¶ https://t.co/DVr6jrE1u0   \n",
       "16971  Thank you @LindseyGrahamSC &amp; @realDonaldTrump for everything #MAGA #KAG #Trump2020 https://t.co/QZUlkGh7hy                                 \n",
       "\n",
       "       sentiment_class  \n",
       "13653  4                \n",
       "2959   4                \n",
       "21449  4                \n",
       "16003  4                \n",
       "5737   4                \n",
       "20268  4                \n",
       "19525  4                \n",
       "25060  4                \n",
       "12448  4                \n",
       "16971  4                "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter 10 positive tweets: \n",
    "print(\"10 random positive tweets and sentiment classes:\")\n",
    "data[(data['sentiment_class'] == 4) | (data['sentiment_class'] == 5)].sample(n=10)[['Tweet', 'sentiment_class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the sentiment scores for sentences are quite accurate in capturing the sentiments of the tweets. From the examples above, we clearly saw that the negative and positive tweets all have emotion words that clearly indicate the perception about the particular subject or candidate. On the otherhand, 8/10 neutral tweets are news related with indifferent tones about the voting process information, accessment on the potential outcomes, etc.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==> The exercise's conclusion is dratiscally different from that of Leowgriffin's on the rule-based/lexicon-based model such as the SentimentIntensityAnalzyer from VADER Lexicon library when he applied it for his HK's case study. It is noteworthy that the tweet's vocabulary is measured up agaainst a pre-defined dictionary of positive and negative words. So it is important to set the right aim before applying such analysis. In this exercise, instead of assigning a particular subject matter to a sentiment like positive = pro-police/BLM like Leowgriffin, we chose the objective approach in the beginning and created the wordcloud to see common words associated with the candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>cleaned_Tweet</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thekumachan</td>\n",
       "      <td>kamala harris knows win contest\\n\\n\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>realdonaldtrump gained twitter followers last ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>joebiden gained twitter followers last hours i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>mike_pence gained twitter followers last hours...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>kamalaharris gained twitter followers last hou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>ByDionne</td>\n",
       "      <td>ü•≥let's win let's get back</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>Iamjasbirkaur</td>\n",
       "      <td>saving democracy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>enelson6</td>\n",
       "      <td>john cornyn buy bending trumps family</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>ethannichtern</td>\n",
       "      <td>happiness noun \\n\\nthat feeling text banking a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>LdyDisney</td>\n",
       "      <td>get</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20159 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User                                      cleaned_Tweet  \\\n",
       "0        thekumachan              kamala harris knows win contest\\n\\n\\n   \n",
       "1      2020Followers  realdonaldtrump gained twitter followers last ...   \n",
       "2      2020Followers  joebiden gained twitter followers last hours i...   \n",
       "3      2020Followers  mike_pence gained twitter followers last hours...   \n",
       "4      2020Followers  kamalaharris gained twitter followers last hou...   \n",
       "...              ...                                                ...   \n",
       "20154       ByDionne                          ü•≥let's win let's get back   \n",
       "20155  Iamjasbirkaur                                   saving democracy   \n",
       "20156       enelson6              john cornyn buy bending trumps family   \n",
       "20157  ethannichtern  happiness noun \\n\\nthat feeling text banking a...   \n",
       "20158      LdyDisney                                                get   \n",
       "\n",
       "       sentiment_class  \n",
       "0                    5  \n",
       "1                    5  \n",
       "2                    5  \n",
       "3                    5  \n",
       "4                    5  \n",
       "...                ...  \n",
       "20154                5  \n",
       "20155                3  \n",
       "20156                3  \n",
       "20157                5  \n",
       "20158                3  \n",
       "\n",
       "[20159 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the useful columns \n",
    "cleaned_data = data[['User', 'cleaned_Tweet', 'sentiment_class']]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>cleaned_Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thekumachan</td>\n",
       "      <td>kamala harris knows win contest\\n\\n\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>realdonaldtrump gained twitter followers last ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>joebiden gained twitter followers last hours i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>mike_pence gained twitter followers last hours...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020Followers</td>\n",
       "      <td>kamalaharris gained twitter followers last hou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20154</th>\n",
       "      <td>ByDionne</td>\n",
       "      <td>ü•≥let's win let's get back</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>Iamjasbirkaur</td>\n",
       "      <td>saving democracy</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20156</th>\n",
       "      <td>enelson6</td>\n",
       "      <td>john cornyn buy bending trumps family</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20157</th>\n",
       "      <td>ethannichtern</td>\n",
       "      <td>happiness noun \\n\\nthat feeling text banking a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20158</th>\n",
       "      <td>LdyDisney</td>\n",
       "      <td>get</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20159 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                User                                      cleaned_Tweet  \\\n",
       "0        thekumachan              kamala harris knows win contest\\n\\n\\n   \n",
       "1      2020Followers  realdonaldtrump gained twitter followers last ...   \n",
       "2      2020Followers  joebiden gained twitter followers last hours i...   \n",
       "3      2020Followers  mike_pence gained twitter followers last hours...   \n",
       "4      2020Followers  kamalaharris gained twitter followers last hou...   \n",
       "...              ...                                                ...   \n",
       "20154       ByDionne                          ü•≥let's win let's get back   \n",
       "20155  Iamjasbirkaur                                   saving democracy   \n",
       "20156       enelson6              john cornyn buy bending trumps family   \n",
       "20157  ethannichtern  happiness noun \\n\\nthat feeling text banking a...   \n",
       "20158      LdyDisney                                                get   \n",
       "\n",
       "      sentiment  \n",
       "0      positive  \n",
       "1      positive  \n",
       "2      positive  \n",
       "3      positive  \n",
       "4      positive  \n",
       "...         ...  \n",
       "20154  positive  \n",
       "20155   neutral  \n",
       "20156   neutral  \n",
       "20157  positive  \n",
       "20158   neutral  \n",
       "\n",
       "[20159 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the scores into sentiment\n",
    "#Create a new column called \"sentiment_class\"\n",
    "sentimentclass_translate = []\n",
    "\n",
    "for i in range(0, len(cleaned_data)):\n",
    "    #current 'sentimentscore' score:\n",
    "    sentiment = cleaned_data.iloc[i,:]['sentiment_class']\n",
    "    \n",
    "    if (sentiment >=1 and sentiment < 3 ):\n",
    "        sentimentclass_translate.append('negative')\n",
    "    elif (sentiment == 3):\n",
    "        sentimentclass_translate.append('neutral')\n",
    "    elif (sentiment >3 and sentiment <= 5):\n",
    "        sentimentclass_translate.append('positive')\n",
    "        \n",
    "        \n",
    "#Add the new column 'sentiment_class' to the dataframe \n",
    "cleaned_data['sentiment'] = sentimentclass_translate\n",
    "\n",
    "#Drop the 'sentiment_class' column the dataframe \n",
    "cleaned_data.drop(['sentiment_class'] , axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "#Check the new column\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='red' size=\"6\"> **V/ RoBERTa CNN** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking to train the roBERTa model to predict the sentiment (pos, neg, neu) from \"Tweet\". The cool thing about this is we can display what part of the text was influencial in deciding whether the text was positive, negative or neutral. Thus, this is an Unsupervised Learning task because we are learning which part of the sentence determine the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install this package first to use the ü§ó TRANSFORMERS\n",
    "#pip install transformers command\n",
    "#https://huggingface.co/transformers/_modules/transformers/modeling_tf_roberta.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the model to accept the Tensorflow 2.0.1\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.3.1\n"
     ]
    }
   ],
   "source": [
    "#Import additional libraries \n",
    "import tensorflow as tf \n",
    "import tensorflow.keras.backend as K \n",
    "from transformers import * \n",
    "import tokenizers \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.display import display, HTML\n",
    "print('TensorFlow',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>cleaned_Tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>talonlawgroup</td>\n",
       "      <td>please vote republican terrorists people getti...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>Charterediv</td>\n",
       "      <td>us decide fate world rather results th‚Ä¶</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17581</th>\n",
       "      <td>novascripts</td>\n",
       "      <td>still time vote early lines starting get longe...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6969</th>\n",
       "      <td>friend62</td>\n",
       "      <td>read british says minorities targeted social m...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>RemoveThatIdiot</td>\n",
       "      <td>let's gt;\\n\\n amp</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  User                                      cleaned_Tweet  \\\n",
       "1998     talonlawgroup  please vote republican terrorists people getti...   \n",
       "8156       Charterediv            us decide fate world rather results th‚Ä¶   \n",
       "17581      novascripts  still time vote early lines starting get longe...   \n",
       "6969          friend62  read british says minorities targeted social m...   \n",
       "6041   RemoveThatIdiot                                  let's gt;\\n\\n amp   \n",
       "\n",
       "      sentiment  \n",
       "1998   negative  \n",
       "8156    neutral  \n",
       "17581   neutral  \n",
       "6969    neutral  \n",
       "6041   positive  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spliting the dataset into \n",
    "train, test = train_test_split(cleaned_data, test_size = 0.1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **roBERTa Tokenization** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will create a variety of roBERTa inputs and target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'vocab_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1421380a2f70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmerges_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'merges-roberta-base.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0madd_prefix_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'vocab_file'"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 96\n",
    "PATH = '/input/tf-roberta/'\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=PATH+'vocab-roberta-base.json', \n",
    "    merges_file=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_id = {'positive': , 'negative': , 'neutral': }\n",
    "sentiment_tar = {'positive': , 'negative': , 'neutral': }\n",
    "DO_QUES_ANS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = train.shape[0]\n",
    "\n",
    "#Inputs to roBERTa\n",
    "ids = np.ones((ct, MAX_LEN), dtype ='int32')\n",
    "att = np.zeros((ct, MAX_LEN), dtype = 'int32')\n",
    "tok = np.zeros((ct, MAX_LEN), dtype = 'int32')\n",
    "\n",
    "\n",
    "#Question answer targets \n",
    "tar1 = np.zeros((ct, MAX_LEN), dtype = 'int32')\n",
    "tar2 = np.zeros((ct, MAX_LEN), dtype = 'int32')\n",
    "\n",
    "#Segmentation target\n",
    "tar3 = np.zeros((ct, MAX_LEN), dtype = 'int32')\n",
    "\n",
    "#Sentiment target\n",
    "tar4 = np.zeros((ct), dtype = 'int32')\n",
    "\n",
    "#Char centers\n",
    "cha = np.zeros((ct, MAX_LEN), dtype = 'float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(train.shape[0]):\n",
    "    # Find text/ selected_text overlap \n",
    "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
    "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
    "    idx = text1.find(text2)\n",
    "    chars = np.zeros((len(text1)))\n",
    "    chars[idx:idx+len(text2)]=1\n",
    "    if text1[idx-1]==' ': chars[idx-1] = 1 \n",
    "    enc = tokenizer.encode(text1)\n",
    "            \n",
    "    # FIND OFFSETS, CHAR CENTERS\n",
    "    off = []; ii=0; ct = 0\n",
    "    for i,t in enumerate(enc.ids):\n",
    "        w = tokenizer.decode([t])\n",
    "        off.append((ii,ii+len(w)))\n",
    "        ii += len(w)\n",
    "        cha[k,i] = ct + len(w)/2.\n",
    "        ct += len(w)\n",
    "        \n",
    "    # FIND SELECTED TEXT TOKENS\n",
    "    tks = []\n",
    "    for i,(a,b) in enumerate(off):\n",
    "        sm = np.sum(chars[a:b])\n",
    "        if sm>0: tks.append(i)\n",
    "        \n",
    "    # CREATE ROBERTA INPUTS\n",
    "    stok = sentiment_id[train.loc[k,'sentiment']]\n",
    "    ids[k,:len(enc.ids)+2] = [0] + enc.ids + [2]\n",
    "    att[k,:len(enc.ids)+2] = 1\n",
    "    if DO_QUES_ANS: # USE THIS FOR QUESTION ANSWER \n",
    "        ids[k,len(enc.ids)+2:len(enc.ids)+5] = [2] + [stok] + [2]\n",
    "        att[k,len(enc.ids)+2:len(enc.ids)+5] = 1\n",
    "        \n",
    "    # CREATE ROBERTA TARGETS\n",
    "    if len(tks)>0:\n",
    "        tar1[k,tks[0]+1] = 1\n",
    "        tar2[k,tks[-1]+1] = 1\n",
    "    for j in range(len(tks)):\n",
    "        tar3[k,tks[j]+1] = 1\n",
    "    tar4[k] = sentiment_tar[train.loc[k,'sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **roBERTa Model** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Andrew NG has pointed out in his Deep Learning Course, it is much better to use a pretrained model to save time. Therefore, we will used the pretrained roBERTa base model and add a classification head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    q_id = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    q_type = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    q_mask = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    \n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(q_id,attention_mask=q_mask,token_type_ids=q_type)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(0.2)(x[0])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x1 = tf.keras.layers.Dense(3,'softmax')(x1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_type], outputs=x1)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
    "        optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **Train Model** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train on 80% train.csv and validate on 20% train.csv. Our model achieves 80% validation accuracy predicting sentiment from Tweet text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE VALIDATION SET\n",
    "idxT = np.arange(0,4*train.shape[0]//5)\n",
    "idxV = np.arange(4*train.shape[0]//5,train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "    \n",
    "sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "        'cam.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='auto', save_freq='epoch')\n",
    "    \n",
    "model.fit([ids[idxT,],att[idxT,],tok[idxT,]], tar4[idxT], \n",
    "          validation_data = ([ids[idxV,],att[idxV,],tok[idxV,]], tar4[idxV]),\n",
    "          epochs=2, batch_size=32, verbose=1, callbacks=[sv])\n",
    "\n",
    "model.load_weights('cam.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **CAM Extraction Model** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of CAM extraction for image recognition is [here](https://www.kaggle.com/cdeotte/unsupervised-masks-cv-0-60). The basic idea is as follows. When our model classifies a text, it will activate one of three classification outputs (pos, neg, neu). We trace that output backwards to see which words contributed the most to the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW MODEL FROM OLD TO EXTRACT ACTIVATION MAPS\n",
    "all_layer_weights = model.layers[-1].get_weights()[0]\n",
    "cam_model = tf.keras.Model(inputs=model.input, \n",
    "        outputs=(model.layers[-4].output, model.layers[-1].output)) \n",
    "pr = {0:'NEUTRAL',1:'POSITIVE',2:'NEGATIVE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font font color='blue' size=\"5\"> **Display Influential Subtext** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to highlight the text with different colors is from notebook here. The plot above each sentence indicates the strength of influence of the words below. The x axis is the sentence and the y axis is the strenth of influence in determining the sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(100):\n",
    "    k = np.random.choice( np.arange(4*train.shape[0]//5,train.shape[0]))\n",
    "    if train.loc[k,'sentiment']=='neutral': continue #boring\n",
    "    if len(train.loc[k,'text'])>95: continue #too wide for display\n",
    "    \n",
    "    # EXTRACT INFLUENCIAL TEXT\n",
    "    last_conv_output,_, pred_vec = cam_model.predict([ids[k:k+1,:],att[k:k+1,:],tok[k:k+1,:]])\n",
    "    last_conv_output = np.squeeze(last_conv_output)\n",
    "    pred = np.argmax(pred_vec)\n",
    "    layer_weights = all_layer_weights[:, pred]\n",
    "    final_output = np.dot(last_conv_output, layer_weights)\n",
    "    if pr[pred]!=train.loc[k,'sentiment'].upper(): continue #skip misclassified\n",
    "    \n",
    "    # PLOT INFLUENCE VALUE\n",
    "    print()\n",
    "    plt.figure(figsize=(20,3))\n",
    "    idx = np.sum(att[k,])\n",
    "    v = np.argsort(final_output[:idx-1])\n",
    "    mx = final_output[v[-1]]; x = max(-10,-len(v))\n",
    "    mn = final_output[v[x]]\n",
    "    plt.plot(cha[k,:idx-2],final_output[1:idx-1],'o-')\n",
    "    plt.plot([1,95],[mn,mn],':')\n",
    "    plt.xlim((0,95))\n",
    "    plt.yticks([]); plt.xticks([])\n",
    "    plt.title('Train row %i. Predict %s.   True label is %s'%(k,pr[pred],train.loc[k,'sentiment']),size=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # DISPLAY ACTIVATION TEXT\n",
    "    html = ''\n",
    "    for j in range(1,idx):\n",
    "        x = (final_output[j]-mn)/(mx-mn)\n",
    "        html += \"<span style='background:{};font-family:monospace'>\".format('rgba(255,255,0,%f)'%x)\n",
    "        html += tokenizer.decode( [ids[k,j]] )\n",
    "        html += \"</span>\"\n",
    "    html += \" (predict)\"\n",
    "    display(HTML(html))\n",
    "\n",
    "    # DISPLAY TRUE SELECTED TEXT\n",
    "    text1 = \" \".join(train.loc[k,'text'].lower().split()) \n",
    "    text2 = \" \".join(train.loc[k,'selected_text'].lower().split())\n",
    "    sp = text1.split(text2)\n",
    "    html = \"<span style='font-family:monospace'>\"+sp[0]+\"</span>\"\n",
    "    for j in range(1,len(sp)):\n",
    "        html += \"<span style='background:yellow;font-family:monospace'>\"+text2+'</span>'\n",
    "        html += \"<span style='font-family:monospace'>\"+sp[j]+\"</span>\"\n",
    "    html += \" (true)\"\n",
    "    display(HTML(html))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
